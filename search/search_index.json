{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Snakemake workflow documentation","text":"<p>Documentation for Snakemake workflows development.</p>"},{"location":"#contents","title":"Contents","text":"<p>Snakemake framework, its basics, and basic setup is presented in the Introduction. Conventions about the workflow structure are described in the Structure section. Guide how to run workflow, both locally and in cluster, is in the Running section. At last, some details about the workflow development process are presented in the Development section.</p>"},{"location":"development/","title":"Development","text":"<p>In this section, we talk about the development process. It is advised to start by using the github template and following the README there.</p>"},{"location":"development/#automatic-linting-and-formatting","title":"Automatic linting and formatting","text":"<p>It is a good practice to run linting and formatting. We can utilize <code>pre-commit</code> to run it automatically.</p> <p>First, you need to install <code>pre_commit</code> in your development environment.</p> <p>Secondly, you need to create pre_commit config named <code>.pre-commit-config.yaml</code>, see example</p> <p>Then at last set up pre-commit using:</p> <p><code>pre-commit install</code></p> <p>Now before any commit, a defined set of actions will be performed and information will be printed out about the results. Sometimes, changes will automatically fixed, or you will be prompted to fix them on your own.</p>"},{"location":"development/#testing","title":"Testing","text":"<p>There should always be a possibility to quickly test the workflow. Tests should be bundled together with the workflow repository, in the <code>.tests</code> directory.</p> <p>In the test directory there should be some mock data and test config or multiple test configs.</p> <p>Further, this should be enforced on the repository level. If you created your workflow repository from the template, there is already github action for testing, presuming the existence of <code>.tests</code> directory with valid test config and data.</p>"},{"location":"development/#commit-messages","title":"Commit messages","text":"<p>When committing, you must follow the Conventional Commits spec. Each PR is automatically validated by the GH action.</p> <p>Further, any push (i.e. after merged PR) to the main branch results in an another PR:</p> <ul> <li>a new release following the Semantic Versioning</li> <li>an automatic changelog as parsed from the commit history</li> </ul> <p>Tip</p> <p>Try to write commit messages more in detail so the automatically created changelog could be useful, for example when writing to the users about changes.</p> <p>Tip</p> <p>Try to not bundle all work in one massive commit.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>Snakemake is a python package which needs to be installed prior running the workflows. It can be installed either via <code>pip</code>, or in a designated <code>conda</code> environment. The latter option is preferred, while it is also recommended to use <code>mamba</code> instead of <code>conda</code>. <code>mamba</code> is practically same as <code>conda</code>, but the dependency solver is much faster and it uses the <code>conda-forge</code> channel as the base channel. For instructions on installing <code>mamba</code>, refer to the documentation.</p> <p>With running <code>mamba</code> (or <code>conda</code>), create a new environment with required dependencies, for example:</p> <pre><code>mamba create -c conda-forge -c bioconda --name snakemake_v7_25 python=3.11 \\\n    snakemake=7.25 peppy snakemake-wrapper-utils pre-commit\n</code></pre> <p>Note</p> <p>Snakemake version should be frozen to a specific version to prevent any dependency problems. Furthermore, this should be set for each workflow separately, so the development of each workflow is independent from the others.</p> <p>Also you should distinguish between environment for workflow development and for users running the workflow. For example, users usually use only lite version of the environment, without things formatting or linting stuff.</p>"},{"location":"introduction/#snakemake-basics","title":"Snakemake basics","text":"<p>Snakemake is a workflow automation tool, which uses rules to define functionality. The comprehensive documentation is already provided on the official site.</p> <p>Warning</p> <p>Try to refer only to the documentation of the Snakemake version you declare to use, as some features or their usage can change among versions.</p> <p>Now, that you prepared your conda environment, head to the next section to know more about the workflow code structure.</p>"},{"location":"running/","title":"Running","text":"<p>In this section, we talk about how to run your snakemake workflows. This section should be partially reused when writing README for the users about how to run the workflow.</p>"},{"location":"running/#conda-environments","title":"Conda environments","text":"<p>One of advantages of Snakemake is, that it installs and manages conda environments for you. The same environment is then reused in multiple rules, if they are defined to, and so on. Snakemake defaultly however is not specified to use conda, so you must specify the <code>--use-conda</code> flag in the Snakemake call.</p> <p>Generally, Snakemake install conda environments directly in the working directory, but this can lead to many duplicate environments across projects, so it is a good idea to use <code>--conda-prefix {DIR}</code> argument in the Snakemake call, and define <code>{DIR}</code> a path to the desired directory.</p> <p>Warning</p> <p>There is some possibility of conflicts in case of running a workflow multiple times simultaneously, as each run could be trying to create the same conda environment. This is a rare case. Ideally, you should either be testing the workflow for the first time alone, and then creating multiple parallel runs. Then, as everything was already installed by the first run, there would be no conflicts.</p> <p>More information on the use of conda envs is available here.</p>"},{"location":"running/#useful-arguments","title":"Useful arguments","text":"<p>There is a myriad of arguments to use when running a snakemake workflow. Recommended arguments to use are the aforementioned <code>--use-conda</code> to use conda environments, and the <code>--conda-prefix {DIR}</code> to specify the directory where snakemake will install workflow conda environments.</p> <p>First, it is advised to dry-run the snakemake workflow using <code>--dry-run</code>:</p> <pre><code>snakemake --cores {THREADS} --use-conda --conda-prefix {DIR} --rerun-incomplete --printshellcmds --dry-run\n</code></pre> <p>When the workflow appears to be assembled correctly, user can omit the <code>--dry-run</code> argument to start the execution:</p> <pre><code>snakemake --cores {THREADS} --use-conda --conda-prefix {DIR} --rerun-incomplete --printshellcmds\n</code></pre> <p>For debugging purposes, the user can add <code>--notemp</code> flag to ignore temp() files in snakemake rules, <code>--show-failed-logs</code> to automatically show failed log messages.</p>"},{"location":"running/#running-using-slurm","title":"Running using SLURM","text":"<p>Note</p> <p>Workflows are made to be run using some job manager like SLURM, however you should run the workflow only locally when in the development stage, or when you are testing the workflow. You should distinguish between basic tests where you use mock data and pre-production tests where you use real data. Pre-production tests should be run using SLURM.</p> <p>First, check the official documentation.</p> <p>There are some changes. First, when running the workflow using cluster, jobs are usually run independently. Instead of cores, you provide the number of independent jobs in the <code>--jobs {JOBS}</code> argument. Also, jobs are independently logged, so you need to prepare a directory for cluster logs. You will need create the directory manually as slurm does not create it (or tell the slurm to force create it).</p> <p>Secondly, Snakemake will need to communicate with SLURM about job statuses, there is already a prepared script at the workflow manager repository. The script needs to have set executive permissions.</p> <p>Thirdly, you must provide snakemake how to cancel the job, in case of SLURM it is <code>scancel</code> command.</p> <p>At last, you must define the way how to submit jobs in the <code>--cluster</code> argument. The basic way is:</p> <pre><code>sbatch --partition={STR} --cpus-per-task={INT} --parsable --output=`pwd`/sbatch_logs/%j.log --error=`pwd`/sbatch_logs/%j.err\n</code></pre> <p>Here <code>%j</code> is used to create a log for each cluster job named the same as the job itself. See sbatch documentation for more. Also, you can add other calls before the sbatch call, for example, adding log folder creation before sbatch:</p> <pre><code>mkdir -p `pwd`/sbatch_logs &amp;&amp; sbatch {SBATCH_CALL}\n</code></pre> <p>Warning</p> <p>Parsable flag in sbatch call to SLURM is very important. Without it, snakemake cannot parse job statuses on their own and control the workflow execution in cases where SLURM hangs or fails.</p> <p>To put all together, the final call should be like this:</p> <pre><code>snakemake --jobs {INT} --use-conda --conda-prefix {DIR} --cluster \"mkdir -p `pwd`/sbatch_logs &amp;&amp; sbatch --partition={STR} --cpus-per-task={INT} --parsable --output=`pwd`/sbatch_logs/%j.log --error=`pwd`/sbatch_logs/%j.err\" --cluster-status {STATUS_SCRIPT_PATH} --cluster-cancel scancel {OTHER_SNAKEMAKE_ARGUMENTS}\n</code></pre>"},{"location":"structure/","title":"Workflow structure","text":"<p>The recommended file structure:</p> <pre><code>\u251c\u2500\u2500 config\n\u2502   \u251c\u2500\u2500 config.yaml\n\u2502   \u2514\u2500\u2500 pep/\n\u2502       \u251c\u2500\u2500 config.yaml\n\u2502       \u2514\u2500\u2500 samples.csv\n\u251c\u2500\u2500 results/\n\u2514\u2500\u2500 workflow/\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u251c\u2500\u2500 envs/\n\u2502   \u2502   \u2514\u2500\u2500 {...}.yaml\n\u2502   \u251c\u2500\u2500 report/\n\u2502   \u2502   \u2514\u2500\u2500 {...}.rst\n\u2502   \u251c\u2500\u2500 rules/\n\u2502   \u2502   \u251c\u2500\u2500 common.smk\n\u2502   \u2502   \u2514\u2500\u2500 {...}.smk\n\u2502   \u251c\u2500\u2500 schemas/\n\u2502   \u2502   \u251c\u2500\u2500 config.schema.yaml\n\u2502   \u2502   \u2514\u2500\u2500 samples.schema.yaml\n\u2502   \u2514\u2500\u2500 Snakefile\n</code></pre> <p>Note</p> <p>When creating a new workflow repository, it is recommended to use github template. Follow the README of the template.</p> <p>There are 3 main directories:</p> <ul> <li><code>results</code> - here should be created all workflow-specific outputs.</li> <li><code>config</code> - here should be defined the configuration for workflow-specific   parameters and inputs.</li> <li><code>workflow</code> - here should be defined everything related to the workflow logic.</li> </ul>"},{"location":"structure/#config-directory","title":"Config directory","text":"<p>Workflow should be defined to be configurable, i.e. the user should be provided with the possibility to fine-tune the tools in the workflow. Snakemake recommends using a file in YAML format. This file should also offer possibility to provide external inputs, such as reference genome or various biological databases. At last, there should be also configuration for resources, such as number of threads or size of memory to be used.</p> <p>Note</p> <p>Snakemake expects the configuration in <code>config/config.yaml</code>, so it will be loaded automatically. However, when running snakemake, you can modify this by using <code>--configfile {custom_path}</code>.</p> <p>In this directory there should be configuration of inputs for the workflow. Snakemake recommends using CSV file to allow user to provide inputs with its attributes. Configuration of attributes should be defined in YAML format.</p> <p>We advise to expose as much functionality as possible to the user. This decreases the chance that you, as a developer, will need to make potential future changes to the code, and to allow you to focus on adding new features.</p>"},{"location":"structure/#workflow-directory","title":"Workflow directory","text":"<p>The entrypoint for the Snakemake is the <code>Snakefile</code> file, which defines exactly one rule which is by default the target rule. This rule should be named <code>all</code> by convention and should request the final outputs of the workflow as inputs. Other Snakemake rules or Python code should not be defined here, but only included.</p> <p>Note</p> <p>It is expected of the entrypoint to be named as <code>Snakefile</code> as snakemake expects the entrypoint in <code>workflow/Snakefile</code>.</p>"},{"location":"structure/#rules-subdirectory","title":"Rules subdirectory","text":"<p>Other workflow logic should be put in the subdirectory <code>rules/</code>, Python code for reading configuration and other auxiliary functions should be by convention put into <code>common.smk</code>, whereas pure Snakemake rules should be put into other <code>*.smk</code> files, balancing cohesion and readability of individual <code>.smk</code> files.</p> <p>Warning</p> <p>In <code>Snakefile</code> you should first include <code>common.smk</code>, then include other rules in <code>.smk</code> files, and at last, directly define the <code>all</code> rule.</p> <p>Rules should be written to represent high-level abstraction view of mappings between inputs and outputs, thus, only the simplest processing logic should be defined directly in rule (i.e. readable bash one-liners like using <code>cat</code> for multiple inputs). Processing logic should be abstracted away, either using <code>wrapper</code> directive for external modular scripts, or <code>script</code> directive for internal scripts. Internal scripts should be put into <code>scripts/</code> subdirectory.</p> <p>Note</p> <p>When the script is called via Snakemake, a <code>snakemake</code> object is made available in the script, storing all input and output paths, parameters, threads, and other arguments passed to the specific rule. See the documentation for specific languages.</p> <p>Warning</p> <p>Snakemake files are not included automatically, but must be defined to be included.</p>"},{"location":"structure/#environments-and-reports","title":"Environments and reports","text":"<p>Other stuff that should be defined in <code>workflow/</code> directory are conda environments, report templates and validation schemas. Conda environments should be put in <code>envs/</code> subdirectory, and they should be defined as specific as possible, and they should not contain anything else in addition to the dependencies required by the rule. Even in the case, where one rule has dependencies that are subset of the other rule, environments should still be defined separately to prevent any conflicts.</p> <p>If you use <code>report</code> directive for outputs in Snakemake rules, you can provide custom report templates. These templates should be stored in the <code>report/</code> subdirectory.</p>"},{"location":"structure/#schemas","title":"Schemas","text":"<p>Configuration for the workflow should be validated, so workflow should not fail due to misconfiguration halfway execution. To validate configuration, it is recommended to use validation schemas, that should be defined in <code>schemas/</code> subdirectory. Currently, Snakemake allows JSON or YAML format conforming to the JSON schema specification. Input configuration should be validated as well, e.g. to ensure that required attributes of inputs have been provided.</p> <p>Tip</p> <p>In validation schema, you can supply default values or advanced validation such as minimum values, enumeration and so on.</p> <p>Note</p> <p>Stricter validation means earlier feedback to the user.</p>"},{"location":"structure/#writing-rules","title":"Writing rules","text":"<p>The specifics of writing the rules are available in the documentation.</p>"}]}